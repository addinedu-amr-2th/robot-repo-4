# ROS 프로젝트 스케쥴 정리
### 사전 준비
- 원래 [Deepspeech stt 모델](https://github.com/sooftware/kospeech)을 이용하여 학습해 사용하려 했으나, 컴퓨팅 파워 부족으로 [이미 학습되어 있는 딥러닝 모델](https://github.com/openai/whisper)을 사용하기로 결정. 성능은 양호해보인다. 
- ChatGPT 사전 리서치 : 비용문제 때문에 연습용으로는 curie 모델을 fine-tuning해서 사용하고, 이후 시연시 davich 모델을 fine-tuning해서 사용하게 될 것으로 생각됨. 이를 위한 fine-tune 데이터셋은 어느정도 제작해둠(시나리오 추가 요구)
- TTS 모델은 눈여겨봐둔 모델이 존재하나 다른 모델을 사용하게 될 것으로 생각됨 

### 2023.5.30
- [audioROS](https://github.com/LCAV/audioROS) 패키지를 활용해서 오디오 퍼블리셔, 서브스크라이버 제작. 일정 시간 퍼블리셔가 구동하다 정지하는 현상 해결
  하지만, 음성이 뚝뚝 끊기는 문제 발생. ROS통신의 속도에 한계가 존재해서 딜레이를 청크단위로 끊어서 그런 것으로 생각됨.
  이 문제를 해결하기 위해선 2가지 솔루션이 존재할 것으로 예상됨
  - 1. 한번에 보내는 사이즈를 키워서 슬로우 모션으로 들리는 상태로 STT 모델에 건네주는 것 (이 경우 느린 음원을 STT 모델이 제대로 알아들을까 미지수)
  - 2. 서브스크라이버 측에서 짧은 시간동안 청크를 모아서 짧은 음원을 만들고 STT 모델에 넣어 1,2 글자를 뱉게 해서 이것을 하나의 문장으로 모으는 것
    (주로 [realtime STT](https://github.com/davabase/whisper_real_time/blob/master/transcribe_demo.py)가 이런 방식을 채택하는 것으로 보임.) 

### 2023.5.31
- 오디오 퍼블리셔 토픽 발행 주기를 짧게 하니, 오디오가 끊기는 문제 해결. 소리가 반복해서 들리나, 이는 스피커에서 나온 소리가 다시 마이크로 들어가 생기는 메아리 현상으로 보인다.
  실제 로봇에 적용하려면 TTS로 말하는 동안에는 음성 입력을 받지 않는 상태로 만들어야 할 것이다(까먹지 말자)
  현재 음성 전송을 잘 하기 위한 조건은 다음과 같다
   - 발행하는 쪽의 chunk size는 작을 수록 매끈하다.
   - 발행하는 주기를 짧게 해야 매끈하게 전송된다.

- 현재 3개의 패키지를 만들었다.
    - audio publisher : 음성을 퍼블리쉬 하는 패키지 (청크 단위로 보내는 stream 모듈이 존재)
      - file : tts 모델이 추가된 하위 모듈이 만들어질 것으로 예상 - 그 때 직접 만들어야 할듯
    - audio subscriber : 음성을 받아서 재생하는 패키지 (현재 음성을 받아들이는 audio subsciber 모듈만 존재, 여기에 stt까지 적용시킨 하위 모듈을 추가할 예정)
    - audio inference : msg등 필요한 도구들이 모여있는 패키지 (위의 두 패키지를 실행하기 위해서 필요)

- STT 모델을 audio subscriber에 넣어 stt_subscriber 모듈을 만들어 봤는데, 주피터로 음성을 녹음해서 해독시켰을 때는 정상 해독했으나
  callback함수로 chunk를 모으다 보내는 방식으로 해봤더니 이상하게 번역하는 문제 발생
  subscriber쪽 문제일텐데 어떻게 수정해야 제대로 알아들을지 감이 안온다..
  - Hello라고 말하는데 I'm Sorry라고 해석한다.
 
